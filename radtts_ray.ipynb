{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1467bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import ray\n",
    "# from ray.data.datasource import FastFileMetadataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04830a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lj_df = pd.read_csv(\n",
    "#     \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/lj_for_upload/metadata_formatted_100.txt\",\n",
    "#     sep=\"|\",\n",
    "#     header=None,\n",
    "#     quoting=3,\n",
    "#     names=[\"path\", \"transcript\", \"speaker_id\"], # pitch path is implicit - this should be changed\n",
    "# )\n",
    "\n",
    "# paths = lj_df.path.tolist()\n",
    "# transcripts = lj_df.transcript.tolist()\n",
    "# speaker_ids = lj_df.speaker_id.tolist()\n",
    "\n",
    "# parallelism_length = 400\n",
    "# audio_ds = ray.data.read_binary_files(\n",
    "#     paths,\n",
    "#     parallelism=parallelism_length,\n",
    "#     meta_provider=FastFileMetadataProvider(),\n",
    "#     ray_remote_args={\"num_cpus\": 0.2},\n",
    "# )\n",
    "# audio_ds = audio_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "\n",
    "# paths = ray.data.from_items(paths, parallelism=parallelism_length)\n",
    "# paths_ds = paths.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "\n",
    "# transcripts = ray.data.from_items(transcripts, parallelism=parallelism_length)\n",
    "# transcripts_ds = transcripts.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "\n",
    "# speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "# speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# output_dataset = (\n",
    "#     transcripts_ds.zip(audio_ds)\n",
    "#     .zip(paths_ds)\n",
    "#     .zip(speaker_ids_ds)\n",
    "# )\n",
    "# output_dataset = output_dataset.map_batches(\n",
    "#     lambda table: table.rename(\n",
    "#         columns={\n",
    "#             \"value_1\": \"transcript\",\n",
    "#             \"value_2\": \"audio_bytes\",\n",
    "#             \"value_3\": \"path\",\n",
    "#             \"value_4\": \"speaker_id\"\n",
    "#         }\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ecc268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17675e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import get_ray_dataset, train_func\n",
    "from ray.train.torch import TorchTrainer, TorchCheckpoint, TorchTrainer\n",
    "class TorchCheckpointFixed(TorchCheckpoint):\n",
    "    def __setstate__(self, state: dict):\n",
    "        if \"_data_dict\" in state and state[\"_data_dict\"]:\n",
    "            state = state.copy()\n",
    "            state[\"_data_dict\"] = self._decode_data_dict(state[\"_data_dict\"])\n",
    "        super(TorchCheckpoint, self).__setstate__(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beb9dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 15:09:32,737\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-07 15:09:32,765\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-07 15:09:32,783\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_eccc6979c79037b7d167507f1405cae4.zip' (6.81MiB) to Ray cluster...\n",
      "2023-03-07 15:09:32,871\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_eccc6979c79037b7d167507f1405cae4.zip'.\n",
      "(_get_read_tasks pid=3656, ip=10.0.48.48) 2023-03-07 15:09:34,374\tWARNING file_meta_provider.py:162 -- Expanding 100 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n"
     ]
    }
   ],
   "source": [
    "ray_dataset = get_ray_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3565f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datum = ray_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3997832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from ray.tune import SyncConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53392b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import train_config, model_config\n",
    "train_config['n_group_size'] = model_config['n_group_size']\n",
    "train_config['dur_model_config'] = model_config['dur_model_config']\n",
    "train_config['f0_model_config'] = model_config['f0_model_config']\n",
    "train_config['energy_model_config'] = model_config['energy_model_config']\n",
    "train_config['v_model_config']=model_config['v_model_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335192ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2, use_gpu=True, resources_per_worker=dict(CPU=4, GPU=1)\n",
    "    ),\n",
    "    run_config=RunConfig(\n",
    "        sync_config=SyncConfig(upload_dir=\"s3://uberduck-anyscale-data/checkpoints\")\n",
    "    ),\n",
    "    datasets={\"train\": ray_dataset},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea03c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\n",
    "        \"TORCH_DISTRIBUTED_DEBUG\"\n",
    "    ] = \"DETAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-07 15:16:39</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:03.69        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.4/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 9.0/24 CPUs, 2.0/2 GPUs, 0.0/61.09 GiB heap, 0.0/26.77 GiB objects (0.0/2.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_209d8_00000</td><td>RUNNING </td><td>10.0.48.48:3738</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:09:46,491\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:46,610\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[randomize_block_order]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:49,880\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,809\tWARNING plan.py:528 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,809\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,955\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +26s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +26s) Adding 5 node(s) of type worker-node-type-0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TorchTrainer pid=3738, ip=10.0.48.48) /home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48)   warnings.warn(\n",
      "(RayTrainWorker pid=1124519) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=1124519) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=1124519) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=1124519) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=1124519) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_15-09-35/TorchTrainer_209d8_00000_0_2023-03-07_15-09-37/rank_1/wandb/run-20230307_151001-209d8_00000\n",
      "(RayTrainWorker pid=1124519) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=1124519) wandb: Syncing run TorchTrainer_209d8_00000\n",
      "(RayTrainWorker pid=1124519) wandb: ⭐️ View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=1124519) wandb: 🚀 View run at https://wandb.ai/uberduck/radtts-ray/runs/209d8_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=1124519) Applying spectral norm to text encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=1124519) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=1124519) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=1124519)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=1124519) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=1124519) and\n",
      "(RayTrainWorker pid=1124519) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=1124519)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) Applying spectral norm to context encoder LSTM\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) CUDA AVAILABLE:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_15-09-35/TorchTrainer_209d8_00000_0_2023-03-07_15-09-37/rank_0/wandb/run-20230307_151002-209d8_00000\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Syncing run TorchTrainer_209d8_00000\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: ⭐️ View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: 🚀 View run at https://wandb.ai/uberduck/radtts-ray/runs/209d8_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Applying spectral norm to text encoder LSTM\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) and\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n",
      "(RayTrainWorker pid=1124519) 2023-03-07 15:10:19,948\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:10:20,219\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1124519) 2023-03-07 15:10:21,843\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:10:22,005\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=1124519) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=1124519)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(raylet, ip=10.0.14.59) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.14.59)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.12.220) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.12.220)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.57.173) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.57.173)   aiogrpc.init_grpc_aio()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1m22s) Resized to 136 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(raylet, ip=10.0.21.18) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.21.18)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.55.4) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.55.4)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.58922576904297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=1124519) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=1124519) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=1124519)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(RayTrainWorker pid=1124519)   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) Loss: 66.71593475341797\n",
      "(autoscaler +1m26s) Resized to 184 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.75285339355469\n",
      "(RayTrainWorker pid=1124519) Loss: 66.76640319824219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.75389099121094\n",
      "(RayTrainWorker pid=1124519) Loss: 66.77154541015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.65056610107422\n",
      "(RayTrainWorker pid=1124519) Loss: 66.45819854736328\n",
      "(autoscaler +6m24s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m28s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m34s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m38s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m44s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m48s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m54s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m59s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m4s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m8s) Removing 5 nodes of type worker-node-type-0 (idle).\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e210d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlibrosa_mel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'slaney'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"slaney\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Create a Mel filter-bank.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This produces a linear transformation matrix to project\u001b[0m\n",
       "\u001b[0;34m    FFT bins onto Mel-frequency bins.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    sr        : number > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        sampling rate of the incoming signal\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_fft     : int > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        number of FFT components\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_mels    : int > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        number of Mel bands to generate\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fmin      : float >= 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        lowest frequency (in Hz)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fmax      : float >= 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        highest frequency (in Hz).\u001b[0m\n",
       "\u001b[0;34m        If `None`, use ``fmax = sr / 2.0``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    htk       : bool [scalar]\u001b[0m\n",
       "\u001b[0;34m        use HTK formula instead of Slaney\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    norm : {None, 'slaney', or number} [scalar]\u001b[0m\n",
       "\u001b[0;34m        If 'slaney', divide the triangular mel weights by the width of the mel band\u001b[0m\n",
       "\u001b[0;34m        (area normalization).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        If numeric, use `librosa.util.normalize` to normalize each filter by to unit l_p norm.\u001b[0m\n",
       "\u001b[0;34m        See `librosa.util.normalize` for a full description of supported norm values\u001b[0m\n",
       "\u001b[0;34m        (including `+-np.inf`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Otherwise, leave all the triangles aiming for a peak value of 1.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    dtype : np.dtype\u001b[0m\n",
       "\u001b[0;34m        The data type of the output basis.\u001b[0m\n",
       "\u001b[0;34m        By default, uses 32-bit (single-precision) floating point.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    M         : np.ndarray [shape=(n_mels, 1 + n_fft/2)]\u001b[0m\n",
       "\u001b[0;34m        Mel transform matrix\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    librosa.util.normalize\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    This function caches at level 10.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> melfb = librosa.filters.mel(22050, 2048)\u001b[0m\n",
       "\u001b[0;34m    >>> melfb\u001b[0m\n",
       "\u001b[0;34m    array([[ 0.   ,  0.016, ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           ...,\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ]])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Clip the maximum frequency to 8KHz\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> librosa.filters.mel(22050, 2048, fmax=8000)\u001b[0m\n",
       "\u001b[0;34m    array([[ 0.  ,  0.02, ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           ...,\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ]])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> import matplotlib.pyplot as plt\u001b[0m\n",
       "\u001b[0;34m    >>> fig, ax = plt.subplots()\u001b[0m\n",
       "\u001b[0;34m    >>> img = librosa.display.specshow(melfb, x_axis='linear', ax=ax)\u001b[0m\n",
       "\u001b[0;34m    >>> ax.set(ylabel='Mel filter', title='Mel filter bank')\u001b[0m\n",
       "\u001b[0;34m    >>> fig.colorbar(img, ax=ax)\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mfmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Initialize the weights\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_fft\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Center freqs of each FFT bin\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfftfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# 'Center freqs' of mel bands - uniformly spaced between limits\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmel_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mramps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# lower and upper slopes for all bins\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# .. then intersect them with each other and zero\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"slaney\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0menorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn_mels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0menorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Only check weights if f_mel[0] is positive\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# This means we have an empty channel somewhere\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Empty filters detected in mel frequency basis. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Some channels will produce empty responses. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Try increasing your sampling rate (and fmax) or \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"reducing n_mels.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.10/site-packages/librosa/filters.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??librosa_mel_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85357490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mel in module librosa.filters:\n",
      "\n",
      "mel(sr, n_fft, n_mels=128, fmin=0.0, fmax=None, htk=False, norm='slaney', dtype=<class 'numpy.float32'>)\n",
      "    Create a Mel filter-bank.\n",
      "    \n",
      "    This produces a linear transformation matrix to project\n",
      "    FFT bins onto Mel-frequency bins.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sr        : number > 0 [scalar]\n",
      "        sampling rate of the incoming signal\n",
      "    \n",
      "    n_fft     : int > 0 [scalar]\n",
      "        number of FFT components\n",
      "    \n",
      "    n_mels    : int > 0 [scalar]\n",
      "        number of Mel bands to generate\n",
      "    \n",
      "    fmin      : float >= 0 [scalar]\n",
      "        lowest frequency (in Hz)\n",
      "    \n",
      "    fmax      : float >= 0 [scalar]\n",
      "        highest frequency (in Hz).\n",
      "        If `None`, use ``fmax = sr / 2.0``\n",
      "    \n",
      "    htk       : bool [scalar]\n",
      "        use HTK formula instead of Slaney\n",
      "    \n",
      "    norm : {None, 'slaney', or number} [scalar]\n",
      "        If 'slaney', divide the triangular mel weights by the width of the mel band\n",
      "        (area normalization).\n",
      "    \n",
      "        If numeric, use `librosa.util.normalize` to normalize each filter by to unit l_p norm.\n",
      "        See `librosa.util.normalize` for a full description of supported norm values\n",
      "        (including `+-np.inf`).\n",
      "    \n",
      "        Otherwise, leave all the triangles aiming for a peak value of 1.0\n",
      "    \n",
      "    dtype : np.dtype\n",
      "        The data type of the output basis.\n",
      "        By default, uses 32-bit (single-precision) floating point.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    M         : np.ndarray [shape=(n_mels, 1 + n_fft/2)]\n",
      "        Mel transform matrix\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    librosa.util.normalize\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function caches at level 10.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> melfb = librosa.filters.mel(22050, 2048)\n",
      "    >>> melfb\n",
      "    array([[ 0.   ,  0.016, ...,  0.   ,  0.   ],\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
      "           ...,\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ]])\n",
      "    \n",
      "    \n",
      "    Clip the maximum frequency to 8KHz\n",
      "    \n",
      "    >>> librosa.filters.mel(22050, 2048, fmax=8000)\n",
      "    array([[ 0.  ,  0.02, ...,  0.  ,  0.  ],\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
      "           ...,\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ]])\n",
      "    \n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> fig, ax = plt.subplots()\n",
      "    >>> img = librosa.display.specshow(melfb, x_axis='linear', ax=ax)\n",
      "    >>> ax.set(ylabel='Mel filter', title='Mel filter bank')\n",
      "    >>> fig.colorbar(img, ax=ax)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from librosa.filters import mel as librosa_mel_fn\n",
    "help(librosa_mel_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8629e2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "from librosa.util import pad_center\n",
    "librosa.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc82186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_center in module librosa.util.utils:\n",
      "\n",
      "pad_center(data: 'np.ndarray', *, size: 'int', axis: 'int' = -1, **kwargs: 'Any') -> 'np.ndarray'\n",
      "    Pad an array to a target length along a target axis.\n",
      "    \n",
      "    This differs from `np.pad` by centering the data prior to padding,\n",
      "    analogous to `str.center`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> # Generate a vector\n",
      "    >>> data = np.ones(5)\n",
      "    >>> librosa.util.pad_center(data, size=10, mode='constant')\n",
      "    array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.])\n",
      "    \n",
      "    >>> # Pad a matrix along its first dimension\n",
      "    >>> data = np.ones((3, 5))\n",
      "    >>> librosa.util.pad_center(data, size=7, axis=0)\n",
      "    array([[ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.]])\n",
      "    >>> # Or its second dimension\n",
      "    >>> librosa.util.pad_center(data, size=7, axis=1)\n",
      "    array([[ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
      "           [ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
      "           [ 0.,  1.,  1.,  1.,  1.,  1.,  0.]])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : np.ndarray\n",
      "        Vector to be padded and centered\n",
      "    size : int >= len(data) [scalar]\n",
      "        Length to pad ``data``\n",
      "    axis : int\n",
      "        Axis along which to pad and center the data\n",
      "    **kwargs : additional keyword arguments\n",
      "        arguments passed to `np.pad`\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data_padded : np.ndarray\n",
      "        ``data`` centered and padded to length ``size`` along the\n",
      "        specified axis\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ParameterError\n",
      "        If ``size < data.shape[axis]``\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.pad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pad_center\n",
    "help(pad_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f2d9a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_center() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpad_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: pad_center() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pad_center(np.ones(1000), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba62366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.8.1\n",
      "  Using cached librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.22.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.2.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (23.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.55.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.10.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.2.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (5.1.1)\n",
      "Requirement already satisfied: setuptools in /home/ray/anaconda3/lib/python3.10/site-packages (from numba>=0.43.0->librosa==0.8.1) (67.4.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/ray/anaconda3/lib/python3.10/site-packages (from numba>=0.43.0->librosa==0.8.1) (0.38.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (2.28.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/ray/anaconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2022.12.7)\n",
      "Installing collected packages: librosa\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.0\n",
      "    Uninstalling librosa-0.10.0:\n",
      "      Successfully uninstalled librosa-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tts 0.11.1 requires cython==0.29.28, but you have cython 0.29.33 which is incompatible.\n",
      "tts 0.11.1 requires inflect==5.6.0, but you have inflect 6.0.2 which is incompatible.\n",
      "tts 0.11.1 requires librosa==0.8.0, but you have librosa 0.8.1 which is incompatible.\n",
      "tts 0.11.1 requires numpy==1.22.4; python_version == \"3.10\", but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed librosa-0.8.1\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install librosa==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1868cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ray\n",
    "parallelism_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636e6cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:54:26,264\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-06 16:54:26,291\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-06 16:54:26,316\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip' (6.75MiB) to Ray cluster...\n",
      "2023-03-06 16:54:26,438\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip'.\n"
     ]
    }
   ],
   "source": [
    "lj_df = pd.read_csv(\n",
    "    \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/lj_for_upload/metadata_formatted_100_edited.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    quoting=3,\n",
    "    names=[\"path\", \"transcript\", \"speaker_id\"], # pitch path is implicit - this should be changed\n",
    ")\n",
    "speaker_ids = lj_df.speaker_id.tolist()\n",
    "speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "    lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77a5ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>have now come into general use and are obvious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>a little reduced in ugliness. The design of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and the whole effect is a little too gray, owi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>It must be remembered, however, that most mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and these somewhat wiry letters are suitable f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  \\\n",
       "0   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "1   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "2   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "3   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "4   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "..                                                ...   \n",
       "95  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "96  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "97  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "98  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "99  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "\n",
       "                                           transcript  speaker_id  \n",
       "0   Printing, in the only sense with which we are ...           0  \n",
       "1                      in being comparatively modern.           0  \n",
       "2   For although the Chinese took impressions from...           0  \n",
       "3   produced the block books, which were the immed...           0  \n",
       "4   the invention of movable metal letters in the ...           0  \n",
       "..                                                ...         ...  \n",
       "95  have now come into general use and are obvious...           0  \n",
       "96  a little reduced in ugliness. The design of th...           0  \n",
       "97  and the whole effect is a little too gray, owi...           0  \n",
       "98  It must be remembered, however, that most mode...           0  \n",
       "99  and these somewhat wiry letters are suitable f...           0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f777244",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = speaker_ids_ds.map_batches(\n",
    "    lambda table: table.rename(\n",
    "        columns={\n",
    "\n",
    "            \"value_1\": \"speaker_id\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97eeeffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'speaker_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'speaker_id'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +2s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +2s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +12s) Removing 2 nodes of type worker-node-type-0 (idle).\n"
     ]
    }
   ],
   "source": [
    "output_dataset.speaker_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc86fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:50:22,749\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)->MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>)->MapBatches(<lambda>): 100%|██████████| 100/100 [00:03<00:00, 28.88it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3e14cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     lj_df = pd.read_csv(\n",
    "#         \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/vctk_mic1/all_with_embs.txt\",\n",
    "#         sep=\"|\",\n",
    "#         header=None,\n",
    "#         quoting=3,\n",
    "#         names=[\"path\", \"speaker_id\", \"transcript\", \"dataset_audio_file_id\", \"emb_path\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05aff22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lj_df['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a5aa798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts_ds = ray.data.from_items(transcripts, parallelism=parallelism_length)\n",
    "# speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "# dataset_audio_file_ids = ray.data.from_items(\n",
    "#     dataset_audio_files, parallelism=parallelism_length\n",
    "# )\n",
    "\n",
    "# pitch_paths_ds = ray.data.read_binary_files(\n",
    "#     pitch_paths,\n",
    "#     parallelism=parallelism_length,\n",
    "#     meta_provider=FastFileMetadataProvider(),\n",
    "#     ray_remote_args={\"num_cpus\": 0.2},\n",
    "# )\n",
    "\n",
    "# audio_ds = audio_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# transcripts_ds = transcripts_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# dataset_audio_file_ids = dataset_audio_file_ids.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# paths_ds = paths.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "# pitches_paths_ds = pitch_paths_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fa88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
